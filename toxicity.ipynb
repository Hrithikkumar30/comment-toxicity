{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.8.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.46.1)\n",
      "Collecting python_version>\"3.7\" (from tensorflow-gpu)\n",
      "  Using cached python_version-0.0.2-py2.py3-none-any.whl (3.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sklearn) (1.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Building wheels for collected packages: tensorflow-gpu\n",
      "  Building wheel for tensorflow-gpu (setup.py): started\n",
      "  Building wheel for tensorflow-gpu (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for tensorflow-gpu\n",
      "Failed to build tensorflow-gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [18 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\hrith\\AppData\\Local\\Temp\\pip-install-3r91fww9\\tensorflow-gpu_648f80a254ab422c8ff52f46139543fe\\setup.py\", line 37, in <module>\n",
      "          raise Exception(TF_REMOVAL_WARNING)\n",
      "      Exception:\n",
      "      \n",
      "      =========================================================\n",
      "      The \"tensorflow-gpu\" package has been removed!\n",
      "      \n",
      "      Please install \"tensorflow\" instead.\n",
      "      \n",
      "      Other than the name, the two packages have been identical\n",
      "      since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "      information, see: pypi.org/project/tensorflow-gpu\n",
      "      =========================================================\n",
      "      \n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tensorflow-gpu\n",
      "ERROR: Could not build wheels for tensorflow-gpu, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge' , 'train.csv','train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\r\\nMore\\r\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\r\\n\\r\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()\n",
    "df.iloc[3]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -------------------\n",
      "absl-py                      1.0.0\n",
      "aiofiles                     23.2.1\n",
      "altair                       4.2.0\n",
      "anyio                        3.7.1\n",
      "argon2-cffi                  21.3.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "asttokens                    2.0.5\n",
      "astunparse                   1.6.3\n",
      "async-generator              1.10\n",
      "attrs                        21.4.0\n",
      "backcall                     0.2.0\n",
      "beautifulsoup4               4.11.1\n",
      "bleach                       5.0.1\n",
      "blinker                      1.5\n",
      "blis                         0.7.9\n",
      "bs4                          0.0.1\n",
      "cachetools                   5.0.0\n",
      "catalogue                    2.0.8\n",
      "certifi                      2021.10.8\n",
      "cffi                         1.15.1\n",
      "charset-normalizer           2.0.12\n",
      "click                        8.1.3\n",
      "cmake                        3.27.1\n",
      "colorama                     0.4.5\n",
      "commonmark                   0.9.1\n",
      "confection                   0.0.3\n",
      "cssselect                    1.2.0\n",
      "cvlib                        0.2.7\n",
      "cycler                       0.11.0\n",
      "cymem                        2.0.7\n",
      "debugpy                      1.6.2\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "entrypoints                  0.4\n",
      "et-xmlfile                   1.1.0\n",
      "exceptiongroup               1.1.3\n",
      "executing                    0.8.3\n",
      "fastapi                      0.103.0\n",
      "fastjsonschema               2.16.1\n",
      "feedfinder2                  0.0.4\n",
      "feedparser                   6.0.10\n",
      "ffmpy                        0.3.1\n",
      "filelock                     3.8.0\n",
      "Flask                        2.2.2\n",
      "flatbuffers                  2.0\n",
      "fonttools                    4.33.3\n",
      "fsspec                       2023.6.0\n",
      "gast                         0.5.3\n",
      "gitdb                        4.0.9\n",
      "GitPython                    3.1.27\n",
      "google-auth                  2.6.6\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "gradio                       3.41.2\n",
      "gradio_client                0.5.0\n",
      "grpcio                       1.46.1\n",
      "h11                          0.13.0\n",
      "h5py                         3.6.0\n",
      "html5lib                     1.1\n",
      "httpcore                     0.17.3\n",
      "httpx                        0.24.1\n",
      "huggingface-hub              0.16.4\n",
      "idna                         3.3\n",
      "imageio                      2.28.1\n",
      "importlib-metadata           4.12.0\n",
      "importlib-resources          6.0.1\n",
      "imutils                      0.5.4\n",
      "inexactsearch                1.0.2\n",
      "ipykernel                    6.15.1\n",
      "ipython                      8.4.0\n",
      "ipython-genutils             0.2.0\n",
      "ipywidgets                   7.7.1\n",
      "itsdangerous                 2.1.2\n",
      "jedi                         0.18.1\n",
      "jieba3k                      0.35.1\n",
      "Jinja2                       3.1.2\n",
      "joblib                       1.1.0\n",
      "jsonschema                   4.7.2\n",
      "jupyter-client               7.3.4\n",
      "jupyter-core                 4.11.1\n",
      "jupyterlab-pygments          0.2.2\n",
      "jupyterlab-widgets           1.1.1\n",
      "keras                        2.8.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.4.2\n",
      "langcodes                    3.3.0\n",
      "libclang                     14.0.1\n",
      "lxml                         4.9.1\n",
      "Markdown                     3.3.7\n",
      "MarkupSafe                   2.1.1\n",
      "matplotlib                   3.5.1\n",
      "matplotlib-inline            0.1.3\n",
      "mediapipe                    0.8.10\n",
      "MiniSom                      2.3.1\n",
      "mistune                      0.8.4\n",
      "mlxtend                      0.20.0\n",
      "mpmath                       1.2.1\n",
      "murmurhash                   1.0.9\n",
      "mysql-connector-python       8.0.29\n",
      "nbclient                     0.6.6\n",
      "nbconvert                    6.5.0\n",
      "nbformat                     5.4.0\n",
      "nest-asyncio                 1.5.5\n",
      "networkx                     2.8.8\n",
      "newspaper3k                  0.2.8\n",
      "nltk                         3.7\n",
      "notebook                     6.4.12\n",
      "numpy                        1.22.3\n",
      "oauthlib                     3.2.0\n",
      "opencv-contrib-python        4.5.5.64\n",
      "opencv-python                4.5.5.64\n",
      "openpyxl                     3.1.2\n",
      "opt-einsum                   3.3.0\n",
      "orjson                       3.9.5\n",
      "outcome                      1.2.0\n",
      "packaging                    21.3\n",
      "pandas                       1.4.2\n",
      "pandocfilters                1.5.0\n",
      "parso                        0.8.3\n",
      "pathy                        0.8.1\n",
      "patsy                        0.5.3\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       9.1.0\n",
      "pip                          23.2.1\n",
      "plotly                       5.16.1\n",
      "preshed                      3.0.8\n",
      "progressbar                  2.5\n",
      "prometheus-client            0.14.1\n",
      "prompt-toolkit               3.0.30\n",
      "protobuf                     3.20.1\n",
      "psutil                       5.9.1\n",
      "PuLP                         2.6.0\n",
      "pure-eval                    0.2.2\n",
      "pyarrow                      8.0.0\n",
      "pyasn1                       0.4.8\n",
      "pyasn1-modules               0.2.8\n",
      "pycparser                    2.21\n",
      "pydantic                     1.10.2\n",
      "pydeck                       0.7.1\n",
      "pydub                        0.25.1\n",
      "Pygments                     2.12.0\n",
      "Pympler                      1.0.1\n",
      "pyparsing                    3.0.8\n",
      "PyPDF2                       2.11.2\n",
      "pyrsistent                   0.18.1\n",
      "PySocks                      1.7.1\n",
      "python-dateutil              2.8.2\n",
      "python-multipart             0.0.6\n",
      "pytz                         2022.1\n",
      "pytz-deprecation-shim        0.1.0.post0\n",
      "pywin32                      304\n",
      "pywinpty                     2.0.6\n",
      "PyYAML                       6.0\n",
      "pyzmq                        23.2.0\n",
      "regex                        2022.7.9\n",
      "requests                     2.27.1\n",
      "requests-file                1.5.1\n",
      "requests-oauthlib            1.3.1\n",
      "rich                         12.5.1\n",
      "rsa                          4.8\n",
      "scikit-learn                 1.1.1\n",
      "scipy                        1.8.1\n",
      "seaborn                      0.12.1\n",
      "selenium                     4.4.3\n",
      "semantic-version             2.10.0\n",
      "semver                       2.13.0\n",
      "Send2Trash                   1.8.0\n",
      "setuptools                   58.1.0\n",
      "sgmllib3k                    1.0.0\n",
      "silpa-common                 0.3\n",
      "six                          1.16.0\n",
      "skfeature-chappers           1.1.0\n",
      "sklearn                      0.0\n",
      "Slowloris                    0.2.6\n",
      "smart-open                   5.2.1\n",
      "smmap                        5.0.0\n",
      "sniffio                      1.2.0\n",
      "sortedcontainers             2.4.0\n",
      "soundex                      1.1.3\n",
      "soupsieve                    2.3.2.post1\n",
      "spacy                        3.4.3\n",
      "spacy-legacy                 3.0.10\n",
      "spacy-loggers                1.0.3\n",
      "spellchecker                 0.4\n",
      "srsly                        2.4.5\n",
      "stack-data                   0.3.0\n",
      "starlette                    0.27.0\n",
      "statsmodels                  0.13.5\n",
      "streamlit                    1.11.0\n",
      "sympy                        1.10.1\n",
      "tenacity                     8.2.3\n",
      "tensorboard                  2.8.0\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.8.0\n",
      "tensorflow-io-gcs-filesystem 0.25.0\n",
      "termcolor                    1.1.0\n",
      "terminado                    0.15.0\n",
      "textblob                     0.17.1\n",
      "tf-estimator-nightly         2.8.0.dev2021122109\n",
      "thinc                        8.1.5\n",
      "threadpoolctl                3.1.0\n",
      "tinycss2                     1.1.1\n",
      "tinysegmenter                0.3\n",
      "tldextract                   3.4.0\n",
      "tmdbv3api                    1.9.0\n",
      "toml                         0.10.2\n",
      "toolz                        0.12.0\n",
      "tornado                      6.2\n",
      "tqdm                         4.64.0\n",
      "traitlets                    5.3.0\n",
      "trio                         0.21.0\n",
      "trio-websocket               0.9.2\n",
      "typer                        0.7.0\n",
      "typing_extensions            4.7.1\n",
      "tzdata                       2022.1\n",
      "tzlocal                      4.2\n",
      "urllib3                      1.26.9\n",
      "uvicorn                      0.23.2\n",
      "validators                   0.20.0\n",
      "waitress                     2.1.2\n",
      "wasabi                       0.10.1\n",
      "watchdog                     2.1.9\n",
      "wcwidth                      0.2.5\n",
      "webencodings                 0.5.1\n",
      "websockets                   11.0.3\n",
      "Werkzeug                     2.2.2\n",
      "wheel                        0.37.1\n",
      "widgetsnbextension           3.6.1\n",
      "wrapt                        1.14.1\n",
      "wsproto                      1.1.0\n",
      "zipp                         3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras \n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Vectorization process\n",
    "#here seperating the dataset in two variable the all comments into X and all the labels into Y\n",
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values\n",
    "Max_Feature= 150000 #number of words into our vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\r\\nWhy the edits made under my use...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\r\\nMore\\r\\nI can't make any real suggestions...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\r\\n\\r\\nThat...\n",
       "159568    Spitzer \\r\\n\\r\\nUmm, theres no actual article ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\r\\nAnd ... I really don't think you understa...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Vectorization process\n",
    "vectorizer = TextVectorization(max_tokens=Max_Feature, output_sequence_length=1800,output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([  1, 261,   8,  74,  98], dtype=int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer('Helllo world i am good')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc2 in position 5: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mh:\\neural nets\\comment_toxicity\\toxicity.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/neural%20nets/comment_toxicity/toxicity.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vectorizer\u001b[39m.\u001b[39;49mget_vocabulary()\n",
      "File \u001b[1;32mc:\\Users\\hrith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py:448\u001b[0m, in \u001b[0;36mTextVectorization.get_vocabulary\u001b[1;34m(self, include_special_tokens)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_vocabulary\u001b[39m(\u001b[39mself\u001b[39m, include_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    440\u001b[0m   \u001b[39m\"\"\"Returns the current vocabulary of the layer.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \n\u001b[0;32m    442\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39m      vocabulary will not include any padding or OOV tokens.\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lookup_layer\u001b[39m.\u001b[39;49mget_vocabulary(include_special_tokens)\n",
      "File \u001b[1;32mc:\\Users\\hrith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\preprocessing\\index_lookup.py:336\u001b[0m, in \u001b[0;36mIndexLookup.get_vocabulary\u001b[1;34m(self, include_special_tokens)\u001b[0m\n\u001b[0;32m    334\u001b[0m   keys, values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlookup_table\u001b[39m.\u001b[39mexport()\n\u001b[0;32m    335\u001b[0m   vocab, indices \u001b[39m=\u001b[39m (values, keys) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minvert \u001b[39melse\u001b[39;00m (keys, values)\n\u001b[1;32m--> 336\u001b[0m   vocab, indices \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensor_vocab_to_numpy(vocab), indices\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m    337\u001b[0m lookup \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mdefaultdict(\u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moov_token,\n\u001b[0;32m    338\u001b[0m                                  \u001b[39mzip\u001b[39m(indices, vocab))\n\u001b[0;32m    339\u001b[0m vocab \u001b[39m=\u001b[39m [lookup[x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabulary_size())]\n",
      "File \u001b[1;32mc:\\Users\\hrith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\preprocessing\\string_lookup.py:401\u001b[0m, in \u001b[0;36mStringLookup._tensor_vocab_to_numpy\u001b[1;34m(self, vocabulary)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_tensor_vocab_to_numpy\u001b[39m(\u001b[39mself\u001b[39m, vocabulary):\n\u001b[0;32m    400\u001b[0m   vocabulary \u001b[39m=\u001b[39m vocabulary\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m--> 401\u001b[0m   \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mas_text(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m vocabulary])\n",
      "File \u001b[1;32mc:\\Users\\hrith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\preprocessing\\string_lookup.py:401\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_tensor_vocab_to_numpy\u001b[39m(\u001b[39mself\u001b[39m, vocabulary):\n\u001b[0;32m    400\u001b[0m   vocabulary \u001b[39m=\u001b[39m vocabulary\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m--> 401\u001b[0m   \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mas_text(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m vocabulary])\n",
      "File \u001b[1;32mc:\\Users\\hrith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\compat.py:105\u001b[0m, in \u001b[0;36mas_text\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[39mreturn\u001b[39;00m bytes_or_text\n\u001b[0;32m    104\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(bytes_or_text, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m--> 105\u001b[0m   \u001b[39mreturn\u001b[39;00m bytes_or_text\u001b[39m.\u001b[39;49mdecode(encoding)\n\u001b[0;32m    106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mExpected binary or unicode string, got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m bytes_or_text)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc2 in position 5: unexpected end of data"
     ]
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text  = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tensorflow Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset pipeline --- map , cache , shuffle,batch,prefetch\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps prevent bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dropout,Bidirectional,Dense,Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although relu is better than tanh but while using a Lstm architecture we should always use Tanh as activation function for optimal result.\n",
    "\n",
    "In bidirectional LSTM we give the input from both the directions from right to left and from left to right . Make a note this is not a backward propagation this is only the input which is given from both the side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# create the embedding layer\n",
    "model.add(Embedding(Max_Feature+1,32)) #first layer in the nn is embedding layer it helps in creating personality test per word\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))# Although relu is better than\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(6,activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy' , optimizer='Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          4800032   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,891,686\n",
      "Trainable params: 4,891,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6981/6981 [==============================] - 3473s 497ms/step - loss: 0.0624 - val_loss: 0.0464\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train , epochs=1 , validation_data = val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x , batch_y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text =vectorizer('You freaking suck! I am going to hurt you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(batch_x) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(np.expand_dims(input_text , 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    # Unpack the batch \n",
    "    X_true, y_true = batch\n",
    "    # Make a prediction \n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    # Flatten the predictions\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.813847541809082, Recall:0.6990088820457458, Accuracy:0.4704112410545349\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.41.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (0.103.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.5.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (0.16.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (3.5.1)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (1.22.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (3.9.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (21.3)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (9.1.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (1.10.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests~=2.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (2.27.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (4.7.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (0.23.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio-client==0.5.0->gradio) (2023.6.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.7.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.8.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.64.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests~=2.0->gradio) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests~=2.0->gradio) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests~=2.0->gradio) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests~=2.0->gradio) (3.3)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.13.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->gradio) (0.17.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.5)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\hrith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from typing_extensions import deprecated\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('toxicity.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('toxicity.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = vectorizer('hey i freaken hate you!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(np.expand_dims(input_str,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86600375, 0.02435529, 0.41285384, 0.02085379, 0.40476704,\n",
       "        0.07529905]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrith\\AppData\\Local\\Temp\\ipykernel_1572\\2358991581.py:2: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
      "C:\\Users\\hrith\\AppData\\Local\\Temp\\ipykernel_1572\\2358991581.py:2: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
      "C:\\Users\\hrith\\AppData\\Local\\Temp\\ipykernel_1572\\2358991581.py:2: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n"
     ]
    }
   ],
   "source": [
    "interface = gr.Interface(fn=score_comment, \n",
    "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
    "                        outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://9bcf04ebc515d263ef.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9bcf04ebc515d263ef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
